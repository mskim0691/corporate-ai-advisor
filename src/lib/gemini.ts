import { GoogleGenerativeAI } from "@google/generative-ai"
import { GoogleAIFileManager, FileState } from "@google/generative-ai/server"
import { Blob } from "buffer"
import prisma from "./prisma"

// Conditionally import supabase only if env vars are present
const USE_SUPABASE = !!(process.env.NEXT_PUBLIC_SUPABASE_URL && process.env.SUPABASE_SERVICE_KEY)
let supabase: any = null

if (USE_SUPABASE) {
  const { supabase: supabaseClient } = require("./supabase")
  supabase = supabaseClient
}

const genAI = new GoogleGenerativeAI(process.env.GOOGLE_GEMINI_API_KEY || "")
const fileManager = new GoogleAIFileManager(process.env.GOOGLE_GEMINI_API_KEY || "")

// ìºì‹œëœ ëª¨ë¸ ì´ë¦„ (ì„œë²„ ì¬ì‹œì‘ ì‹œê¹Œì§€ ìœ ì§€)
let cachedModelName: string | null = null

interface GeminiModel {
  name: string
  supportedGenerationMethods?: string[]
}

/**
 * ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì‹  Gemini ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
 * ìš°ì„ ìˆœìœ„: Flash > Pro (Flashê°€ ë” ë¹ ë¥´ê³  ë¹„ìš© íš¨ìœ¨ì )
 * ë²„ì „: ìµœì‹  ë²„ì „ ìš°ì„  (2.5 > 2.0 > 1.5)
 */
async function getLatestAvailableModel(): Promise<string> {
  // ì´ë¯¸ ëª¨ë¸ì„ ì„ íƒí–ˆë‹¤ë©´ ìºì‹œëœ ê°’ ì‚¬ìš©
  if (cachedModelName) {
    return cachedModelName
  }

  try {
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1/models?key=${process.env.GOOGLE_GEMINI_API_KEY}`
    )
    const data = await response.json()

    if (!data.models || data.models.length === 0) {
      throw new Error("No models available")
    }

    // generateContentë¥¼ ì§€ì›í•˜ëŠ” ëª¨ë¸ë§Œ í•„í„°ë§
    const availableModels = (data.models as GeminiModel[]).filter(
      (model) =>
        model.supportedGenerationMethods?.includes("generateContent") &&
        model.name.includes("gemini")
    )

    if (availableModels.length === 0) {
      throw new Error("No compatible models found")
    }

    // ëª¨ë¸ ì´ë¦„ì—ì„œ ë²„ì „ ì¶”ì¶œ ë° ì •ë ¬ (ìµœì‹  ë²„ì „ ìš°ì„ )
    const sortedModels = availableModels.sort((a, b) => {
      const aName = a.name.replace("models/", "")
      const bName = b.name.replace("models/", "")

      // Flash ëª¨ë¸ ìš°ì„  (ë” ë¹ ë¥´ê³  ë¹„ìš© íš¨ìœ¨ì )
      const aIsFlash = aName.includes("flash")
      const bIsFlash = bName.includes("flash")
      if (aIsFlash && !bIsFlash) return -1
      if (!aIsFlash && bIsFlash) return 1

      // ë²„ì „ ë²ˆí˜¸ ë¹„êµ (2.5 > 2.0 > 1.5)
      const aVersion = parseFloat(aName.match(/\d+\.\d+/)?.[0] || "0")
      const bVersion = parseFloat(bName.match(/\d+\.\d+/)?.[0] || "0")
      return bVersion - aVersion
    })

    // ìµœì ì˜ ëª¨ë¸ ì„ íƒ
    const selectedModel = sortedModels[0].name.replace("models/", "")
    cachedModelName = selectedModel

    console.log(`ğŸ¤– Selected Gemini model: ${selectedModel}`)
    return selectedModel
  } catch (error) {
    console.error("Error fetching available models:", error)
    // í´ë°±: ì•ˆì •ì ì¸ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©
    cachedModelName = "gemini-2.5-flash"
    console.log(`âš ï¸  Using fallback model: ${cachedModelName}`)
    return cachedModelName
  }
}

export interface AnalysisSlide {
  slideNumber: number
  title: string
  content: string
  chartType?: "none" | "bar" | "pie" | "line"
  chartData?: unknown
  speaker_notes?: string
}

export interface AnalysisResult {
  slides: AnalysisSlide[]
}

export interface TextAnalysisResult {
  analysis: string
}

// The new return type from the fileManager.uploadFile method
type UploadedFile = Awaited<ReturnType<typeof fileManager.uploadFile>>["file"]

export interface UploadedGeminiFile {
  file: UploadedFile
  filename: string
}

interface RawSlideData {
  slideNumber: number
  title: string
  content: string
  speaker_notes?: string
  type?: string
}

/**
 * ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ê°€ì ¸ì˜¤ê³  ë³€ìˆ˜ë¥¼ ì¹˜í™˜í•©ë‹ˆë‹¤.
 */
async function getPrompt(name: string, variables: Record<string, string>): Promise<string> {
  const promptRecord = await prisma.prompt.findUnique({
    where: { name }
  })

  if (!promptRecord) {
    throw new Error(`Prompt not found: ${name}`)
  }

  let prompt = promptRecord.content

  // ë³€ìˆ˜ ì¹˜í™˜
  for (const [key, value] of Object.entries(variables)) {
    const regex = new RegExp(`{{${key}}}`, 'g')
    prompt = prompt.replace(regex, value)
  }

  return prompt
}

/**
 * Downloads a file from Supabase Storage (or local filesystem) and uploads it to Gemini.
 */
export async function uploadFileToGemini(filePath: string, mimeType: string) {
  const fs = await import("fs/promises")
  const path = await import("path")
  const os = await import("os")

  let buffer: Buffer

  if (USE_SUPABASE) {
    // 1. Download from Supabase
    const { data: blob, error: downloadError } = await supabase.storage
      .from("uploads")
      .download(filePath)

    if (downloadError) {
      console.error("Supabase download error:", downloadError)
      throw new Error(`Failed to download file from Supabase: ${filePath}`)
    }

    buffer = Buffer.from(await blob.arrayBuffer())
  } else {
    // 1. Read from local filesystem
    const uploadDir = process.env.UPLOAD_DIR || "./uploads"
    const fullPath = path.join(process.cwd(), uploadDir, filePath)

    try {
      buffer = await fs.readFile(fullPath)
      console.log(`âœ“ File read from local storage: ${fullPath}`)
    } catch (error) {
      console.error(`Local file read error for ${filePath}:`, error)
      throw new Error(`Failed to read file from local storage: ${filePath}`)
    }
  }

  // 2. Upload to Gemini using a temporary file
  try {
    const tempDir = os.tmpdir()
    const tempFilePath = path.join(tempDir, `gemini-upload-${Date.now()}-${filePath.split("/").pop()}`)

    await fs.writeFile(tempFilePath, buffer)

    const displayName = filePath.split("/").pop() || "uploaded-file"

    console.log(`Uploading ${displayName} to Gemini...`)
    const uploadResult = await fileManager.uploadFile(tempFilePath, {
      mimeType,
      displayName,
    })

    // Clean up temp file
    await fs.unlink(tempFilePath)

    console.log(`âœ“ File uploaded: ${uploadResult.file.displayName} (${uploadResult.file.uri})`)

    // Wait until the file is processed and ready
    let file = uploadResult.file
    while (file.state === FileState.PROCESSING) {
      process.stdout.write(".");
      await new Promise(resolve => setTimeout(resolve, 5_000)); // Wait 5 seconds
      file = await fileManager.getFile(file.name);
    }

    if (file.state === FileState.FAILED) {
      throw new Error("File processing failed on Gemini.");
    }

    return file
  } catch (error) {
    console.error(`Gemini upload error for ${filePath}:`, error)
    throw new Error(`Failed to upload file to Gemini.`)
  }
}

/**
 * 1ë‹¨ê³„: í˜„í™©ë¶„ì„ (í˜„í™© ë° ì˜ˆìƒ ë¦¬ìŠ¤í¬)
 */
export async function analyzeInitialRisk(
  companyInfo: {
    companyName: string
    businessNumber: string
    representative: string
    industry?: string
  },
  uploadedFiles: UploadedGeminiFile[],
  additionalRequest?: string
): Promise<TextAnalysisResult> {
  const modelName = await getLatestAvailableModel()
  const model = genAI.getGenerativeModel({ model: modelName })

  const fileList = uploadedFiles.map(f => `- ${f.filename}`).join("\n")

  // ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
  const prompt = await getPrompt('step1-initial-risk-analysis', {
    companyName: companyInfo.companyName,
    businessNumber: companyInfo.businessNumber,
    representative: companyInfo.representative,
    industry: companyInfo.industry ? `**ì—…ì¢…:** ${companyInfo.industry}` : "",
    fileList: fileList,
    additionalRequest: additionalRequest ? `\n**ì¶”ê°€ ë¶„ì„ ìš”ì²­ì‚¬í•­:**\n${additionalRequest}\n` : ""
  })

  try {
    const parts = [
      { text: prompt },
      ...uploadedFiles.map(f => ({
        fileData: {
          mimeType: f.file.mimeType,
          fileUri: f.file.uri
        }
      }))
    ]

    const result = await model.generateContent(parts)
    const response = await result.response
    const text = response.text()

    return {
      analysis: text
    }
  } catch (error) {
    console.error("Gemini API error (initial risk analysis):", error)
    throw new Error("í˜„í™©ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")
  }
}

/**
 * 2ë‹¨ê³„: ì†”ë£¨ì…˜ ë„ì¶œ - Google Search Groundingì„ í™œìš©í•œ ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
 */
export async function analyzeCompanyText(
  companyInfo: {
    companyName: string
    businessNumber: string
    representative: string
    industry?: string
  },
  uploadedFiles: UploadedGeminiFile[],
  additionalRequest?: string
): Promise<TextAnalysisResult> {
  const modelName = await getLatestAvailableModel()

  // Google Search Groundingì„ ìœ„í•œ ë„êµ¬ ì„¤ì •
  const model = genAI.getGenerativeModel({
    model: modelName,
    tools: [
      {
        googleSearch: {} as any
      }
    ] as any
  })

  const fileList = uploadedFiles.map(f => `- ${f.filename}`).join("\n")

  // ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
  const prompt = await getPrompt('step2-solution-sales-script', {
    companyName: companyInfo.companyName,
    businessNumber: companyInfo.businessNumber,
    representative: companyInfo.representative,
    industry: companyInfo.industry ? `**ì—…ì¢…:** ${companyInfo.industry}` : "",
    fileList: fileList,
    additionalRequest: additionalRequest ? `\n**ì¶”ê°€ ì •ë³´:**\n${additionalRequest}\n` : ""
  })

  try {
    const parts = [
      { text: prompt },
      ...uploadedFiles.map(f => ({
        fileData: {
          mimeType: f.file.mimeType,
          fileUri: f.file.uri
        }
      }))
    ]

    console.log(`ğŸ” Starting detailed analysis with Google Search Grounding for ${companyInfo.companyName}...`)

    const result = await model.generateContent(parts)
    const response = await result.response
    const text = response.text()

    console.log(`âœ“ Detailed analysis completed with grounding`)

    return {
      analysis: text
    }
  } catch (error) {
    console.error("Gemini API error (text analysis with grounding):", error)
    throw new Error("AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")
  }
}

/**
 * 3ë‹¨ê³„: í…ìŠ¤íŠ¸ ë¶„ì„ì„ ê¸°ë°˜ìœ¼ë¡œ í”„ë ˆì  í…Œì´ì…˜ ìŠ¬ë¼ì´ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
 */
export async function generatePresentationSlides(
  textAnalysis: string,
  companyName: string
): Promise<AnalysisResult> {
  const modelName = await getLatestAvailableModel()
  const model = genAI.getGenerativeModel({ model: modelName })

  // ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
  const prompt = await getPrompt('step3-presentation-generation', {
    companyName: companyName,
    textAnalysis: textAnalysis
  })

  try {
    const result = await model.generateContent(prompt)
    const response = await result.response
    const text = response.text()

    // JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ê°€ë” ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ì ¸ ë‚˜ì˜¤ëŠ” ê²½ìš° ëŒ€ë¹„)
    let jsonText = text

    // ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
    const codeBlockMatch = text.match(/```(?:json)?\s*(\{[\s\S]*\})\s*```/)
    if (codeBlockMatch) {
      jsonText = codeBlockMatch[1]
    } else {
      const jsonMatch = text.match(/\{[\s\S]*\}/)
      if (jsonMatch) {
        jsonText = jsonMatch[0]
      }
    }

    let parsedData: { slides: RawSlideData[] }
    try {
      parsedData = JSON.parse(jsonText)
    } catch (parseError) {
      console.error("JSON parse error:", parseError)
      console.error("Problematic JSON (first 1000 chars):", jsonText.substring(0, 1000))
      console.error("Problematic JSON (around error position):", jsonText.substring(4700, 4900))

      // ì¼ë°˜ì ì¸ JSON ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì œ ì‹œë„ ìˆ˜ì •
      try {
        // ì˜ëª»ëœ ë°±ìŠ¬ë˜ì‹œ ì‹œí€€ìŠ¤ ìˆ˜ì • ì‹œë„
        const fixedJson = jsonText
          .replace(/\\(?!["\\/bfnrtu])/g, '\\\\')  // ìœ íš¨í•˜ì§€ ì•Šì€ ì´ìŠ¤ì¼€ì´í”„ ì‹œí€€ìŠ¤ ìˆ˜ì •

        parsedData = JSON.parse(fixedJson)
        console.log("JSON parsing succeeded after fixing escape sequences")
      } catch (retryError) {
        console.error("JSON parsing failed even after attempting fixes")
        throw new Error("Invalid JSON response from AI")
      }
    }

    // AnalysisResult íƒ€ì…ìœ¼ë¡œ ë§¤í•‘
    const analysisResult: AnalysisResult = {
      slides: parsedData.slides.map((slide) => ({
        slideNumber: slide.slideNumber,
        title: slide.title,
        content: slide.content,
        // speaker_notesê°€ API ì‘ë‹µì— ìˆë‹¤ë©´ í¬í•¨ (ì˜µì…”ë„)
        speaker_notes: slide.speaker_notes || "",
        chartType: "none" as const,
      }))
    }

    return analysisResult
  } catch (error) {
    console.error("Gemini API error (presentation generation):", error)
    throw new Error("í”„ë ˆì  í…Œì´ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")
  }
}